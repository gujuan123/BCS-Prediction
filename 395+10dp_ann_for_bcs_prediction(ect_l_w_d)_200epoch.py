# -*- coding: utf-8 -*-
"""Chapter_3_395+10dp_ANN_for_BCS_Prediction(ECT_L_W_D)_200epoch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fn8g6inrf1DXdC1w2sWaV9VtMbnzpGnG
"""

from google.colab import files
uploaded = files.upload()
#395 data (4input_ECT L W D)

from google.colab import files
uploaded = files.upload()
#Physical tested data(10 dimensions)

# first neural network with keras make predictions
import pandas as pd
import io
import numpy
from numpy import loadtxt
from keras.models import Sequential
from keras.layers import Dense
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
#import pdb
for i in range(70):
    #def pdb_test():
    # load the dataset1
    dataset1 = pd.read_csv('395 data (4input_ECT L W D).csv')
    X_train = dataset1.iloc[:, 0:4]
    y_train = dataset1.iloc[:, [4]]

    # load the dataset1
    dataset2 = pd.read_csv('Physical tested data(10 dimensions).csv')
    X_test = dataset2.iloc[:, 0:4]
    y_test = dataset2.iloc[:, [4]]

    # split into input (X) and output (y) variables
    #X = dataset.iloc[:, 0:4]
    #y = dataset.iloc[:, 4]
    X_train = X_train.values
    y_train = y_train.values
    X_test = X_test.values
    y_test = y_test.values

    # reshape arrays into into rows and cols
    #X = X.reshape(395, 4)
    #y = y.reshape(len(y), 1)
    #y = y.reshape(395, 1)

    # === Fit scalers on training data only ===
    scale_X = MinMaxScaler()
    scale_y = MinMaxScaler()
    X_train_scaled = scale_X.fit_transform(X_train)
    y_train_scaled = scale_y.fit_transform(y_train)

    # === Transform test data using same scalers ===
    X_test_scaled = scale_X.transform(X_test)
    y_test_scaled = scale_y.transform(y_test)

    # separately scale the input and output variables
    #scale_X = MinMaxScaler()
    #X = scale_X.fit_transform(X)
    #scale_y = MinMaxScaler()
    #y = scale_y.fit_transform(y)
    #print(X.min(), X.max(), y.min(), y.max())

    # define the keras model
    model = Sequential()
    model.add(Dense(24, input_dim=4, activation='relu'))
    #model.add(Dense(15, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    # compile the keras model
    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])
    #pdb.set_trace()
    # split into 90% for train and 10% for test
    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)
    # Fit the model
    #history = model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=200,batch_size=10)
    history = model.fit(X_train_scaled, y_train_scaled, validation_data=(X_test_scaled, y_test_scaled), epochs=200, batch_size=10)



    # summarize history for loss
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('model loss')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')
    plt.show()
    # summarize history for accuracy
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.title('model accuracy')
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')
    plt.show()

    # make predictions for the input data
    #predictions = model.predict(X)
    #X = (scale_X).inverse_transform(X)
    #y = (scale_y).inverse_transform(y)
    #excepts = (scale_y).inverse_transform(predictions)

    # === Predictions and inverse scaling ===
    predictions_train_scaled = model.predict(X_train_scaled)
    predictions_test_scaled = model.predict(X_test_scaled)

    X_train_original = scale_X.inverse_transform(X_train_scaled)
    y_train_original = scale_y.inverse_transform(y_train_scaled)
    predictions_train_original = scale_y.inverse_transform(predictions_train_scaled)

    X_test_original = scale_X.inverse_transform(X_test_scaled)
    y_test_original = scale_y.inverse_transform(y_test_scaled)
    predictions_test_original = scale_y.inverse_transform(predictions_test_scaled)
    # === Calculate and print errors ===
    sum_y_train_error = 0
    for i in range(len(X_train_original)):
        print('Train %s => %.2f (expected %.2f)' % (X_train_original[i].tolist(), predictions_train_original[i], y_train_original[i]))
        sum_y_train_error += abs(predictions_train_original[i] - y_train_original[i]) / predictions_train_original[i]
    average_y_train_error = sum_y_train_error / len(X_train_original)
    print("Average train error:", average_y_train_error)

    sum_y_test_error = 0
    for i in range(len(X_test_original)):
        print('Test %s => %.2f (expected %.2f)' % (X_test_original[i].tolist(), predictions_test_original[i], y_test_original[i]))
        sum_y_test_error += abs(predictions_test_original[i] - y_test_original[i]) / predictions_test_original[i]
    average_y_test_error = sum_y_test_error / len(X_test_original)
    print("Average test error:", average_y_test_error)

    print('MSE of train data: %.3f' % mean_squared_error(y_train_original, predictions_train_original))
    print('MSE of test data: %.3f' % mean_squared_error(y_test_original, predictions_test_original))
